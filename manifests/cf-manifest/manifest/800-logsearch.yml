releases:
- name: logsearch
  url: https://bosh.io/d/github.com/logsearch/logsearch-boshrelease?v=203.0.0
  version: 203.0.0
  sha1: 4872c3d89fb2587d844dabbc93b124fb43b720d8
- name: logsearch-for-cloudfoundry
  version: 20161208

jobs:
- (( append ))
- name: queue
  release: logsearch
  azs: [z1, z2]
  templates:
  - name: queue
    release: logsearch
  vm_type: small
  stemcell: default
  instances: 2
  networks:
  - name: cf
    static_ips:
      - 10.0.16.13
      - 10.0.17.13
  persistent_disk_type: queue

- name: parser_z1
  release: logsearch
  azs: [z1]
  templates:
  - name: parser
    release: logsearch
  - name: logsearch-for-cloudfoundry-filters
    release: logsearch-for-cloudfoundry
  vm_type: small
  stemcell: default
  instances: 1
  networks:
  - name: cf
    static_ips:
      - 10.0.16.14
  properties:
    redis:
      host: (( grab jobs.queue.networks.cf.static_ips.[0] ))
    logstash: (( grab properties.parser_logstash ))
    logstash_parser:
      filters:
        - logstash: /var/vcap/packages/logsearch-for-cloudfoundry-filters/logstash-filters-default.conf

- name: parser_z2
  release: logsearch
  azs: [z2]
  templates:
  - name: parser
    release: logsearch
  - name: logsearch-for-cloudfoundry-filters
    release: logsearch-for-cloudfoundry
  vm_type: small
  stemcell: default
  instances: 1
  networks:
  - name: cf
    static_ips:
      - 10.0.17.14
  properties:
    redis:
      host: (( grab jobs.queue.networks.cf.static_ips.[1] ))
    logstash: (( grab properties.parser_logstash ))
    logstash_parser:
      filters:
        - logstash: /var/vcap/packages/logsearch-for-cloudfoundry-filters/logstash-filters-default.conf

- name: elasticsearch_master
  release: logsearch
  azs: [z1, z2, z3]
  templates:
  - name: elasticsearch
    release: logsearch
  vm_type: elasticsearch_master
  stemcell: default
  instances: 3
  networks:
  - name: cf
    static_ips:
      - 10.0.16.10
      - 10.0.17.10
      - 10.0.18.10
  persistent_disk_type: elasticsearch_master
  properties:
    elasticsearch:
      node:
        allow_master: true
        allow_data: true
      discovery:
        minimum_master_nodes: 2
      master_hosts: (( grab properties.elasticsearch.master_hosts ))

- name: maintenance
  instances: 1
  release: logsearch
  azs: [z1, z2]
  templates:
  - name: elasticsearch_config
    release: logsearch
  - name: curator
    release: logsearch
  - name: logsearch-for-cloudfoundry-filters
    release: logsearch-for-cloudfoundry
  vm_type: small
  stemcell: default
  networks:
  - name: cf
  properties:
    elasticsearch_config:
      templates:
      - index_template: /var/vcap/packages/logsearch-for-cloudfoundry-filters/logs-template.json

- name: kibana
  release: logsearch
  azs: [z1, z2]
  templates:
  - name: kibana
    release: logsearch
  - name: haproxy
    release: logsearch
  vm_type: kibana
  stemcell: default
  instances: 1
  networks:
  - name: cf

- name: upload-kibana-objects
  release: logsearch-for-cloudfoundry
  azs: [z1]
  vm_type: small
  stemcell: default
  lifecycle: errand
  instances: 1
  templates:
  - {name: upload-kibana-objects, release: logsearch-for-cloudfoundry}
  networks:
  - name: cf
  properties:
    elasticsearch:
      host: (( grab jobs.elasticsearch_master.networks.cf.static_ips.[0] ))
      port: 9200
    kibana_objects:
      upload_data_files:
        - /var/vcap/packages/logsearch-for-cloudfoundry-filters/kibana-objects-bulk-json

- name: ingestor_z1
  release: logsearch
  azs: [z1]
  templates:
  - name: ingestor_syslog
    release: logsearch
  - name: ingestor_relp
    release: logsearch
  vm_type: ingestor
  stemcell: default
  instances: 1
  networks:
  - name: cf
    default: [gateway, dns]
    static_ips:
      - 10.0.16.12
  properties:
    redis:
      host: (( grab jobs.queue.networks.cf.static_ips.[0] ))
  update:
    serial: true

- name: ingestor_z2
  release: logsearch
  azs: [z2]
  templates:
  - name: ingestor_syslog
    release: logsearch
  - name: ingestor_relp
    release: logsearch
  vm_type: ingestor
  stemcell: default
  instances: 1
  networks:
  - name: cf
    default: [gateway, dns]
    static_ips:
      - 10.0.17.12
  properties:
    redis:
      host: (( grab jobs.queue.networks.cf.static_ips.[1] ))
  update:
    serial: true

properties:
  syslog_daemon_config:
    enable: false
  parser_logstash:
    output:
      elasticsearch:
        data_hosts: (( grab properties.elasticsearch.master_hosts ))
  curator:
    purge_logs:
      retention_period: 30
    elasticsearch:
      host: (( grab terraform_outputs.logsearch_elastic_master_elb_dns_name ))
  elasticsearch:
    master_hosts: (( grab jobs.elasticsearch_master.networks.cf.static_ips[0] jobs.elasticsearch_master.networks.cf.static_ips[1] jobs.elasticsearch_master.networks.cf.static_ips[2] ))
    cluster_name: logsearch
  kibana:
    elasticsearch:
      host: (( grab terraform_outputs.logsearch_elastic_master_elb_dns_name ))
      port: 9200
  haproxy:
    kibana:
      auth:
        username: admin
        password: (( grab secrets.kibana_admin_password ))
      backend_servers: ["localhost"]
      backend_port: 5601
      inbound_port: 5602
  elasticsearch_config:
    elasticsearch:
      host: (( grab terraform_outputs.logsearch_elastic_master_elb_dns_name ))
    templates:
      - index_template: /var/vcap/packages/logsearch-config/default-mappings.json
  logstash_parser:
    debug: false
    elasticsearch_index: "logs-%{[@metadata][index]}-%{+YYYY.MM.dd}"
    elasticsearch_index_type: "%{@type}"
    deployment_dictionary: /var/vcap/jobs/logsearch-for-cloudfoundry-filters/config/deployment_lookup.yml
    deployment_name:
      cf: "(( grab terraform_outputs.environment  ))"
      diego: "(( grab terraform_outputs.environment  ))"

